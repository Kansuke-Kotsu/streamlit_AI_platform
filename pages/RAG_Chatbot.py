import streamlit as st
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from serpapi import GoogleSearch
import requests
from bs4 import BeautifulSoup
import os
import tempfile
import re

# Streamlitã®ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ğŸ“„ Google Search RAG Chatbot")

# ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title("ğŸ“„ Retrieval-Augmented Generation (RAG) Chatbot with Google Search")
st.write("""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«åŸºã¥ã„ã¦Googleæ¤œç´¢ã‚’è¡Œã„ã€æœ€æ–°ã®æƒ…å ±ã‚’å–å¾—ã—ã¦å›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚
ã“ã®ã‚¢ãƒ—ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€OpenAIã¨SerpAPIã®APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒªãƒ³ã‚¯ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚
(OpenAI: https://platform.openai.com/account/api-keys, 
SerpAPI: https://serpapi.com/)
""")

# APIã‚­ãƒ¼ã®å–å¾—ã¨ç¢ºèª
if 'openai_api_key' not in st.session_state:
    st.session_state['openai_api_key'] = ""
if 'serpapi_api_key' not in st.session_state:
    st.session_state['serpapi_api_key'] = ""

# ç¢ºèª
if not st.session_state['openai_api_key'] or not st.session_state['serpapi_api_key']:
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    with st.form("apikey_form"):
        openai_api_key = st.text_input("Enter your OpenAI API Key", type="password", value=st.session_state['openai_api_key'])
        serpapi_api_key = st.text_input("Enter your SerpAPI Key", type="password", value=st.session_state['serpapi_api_key'])
        submitted = st.form_submit_button("Save API Keys")

        if submitted:
            st.session_state['openai_api_key'] = openai_api_key
            st.session_state['serpapi_api_key'] = serpapi_api_key
            if st.session_state['openai_api_key']=="":
                st.session_state['openai_api_key'] = st.secrets["OPENAI_API_KEY"]
            if st.session_state['serpapi_api_key']=="":
                st.session_state['serpapi_api_key'] = st.secrets["serpapi_api_key"]
            st.success("APIã‚­ãƒ¼ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    st.warning("OpenAI APIã‚­ãƒ¼ã¨SerpAPIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

openai_api_key = st.session_state['openai_api_key']
serpapi_api_key = st.session_state['serpapi_api_key']

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
with st.sidebar:
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š")
    chunk_size = st.number_input("Chunk Size", min_value=100, max_value=5000, value=1000, step=100)
    chunk_overlap = st.number_input("Chunk Overlap", min_value=0, max_value=1000, value=200, step=50)
    num_results = st.number_input("Number of Google Search Results", min_value=1, max_value=10, value=3, step=1)
    search_method = st.selectbox("æ¤œç´¢æ–¹æ³•", ["ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"])

# è³ªå•ã®å…¥åŠ›ã¨æ¤œç´¢çµæœã®ä¿å­˜
if "search_results" not in st.session_state:
    st.session_state["search_results"] = None

question = st.text_area(
    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
    placeholder="ä¾‹: æœ€æ–°ã®AIæŠ€è¡“ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
)

if st.button("Googleæ¤œç´¢ã‚’å®Ÿè¡Œ"):
    if not question:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("Googleæ¤œç´¢ã§æƒ…å ±ã‚’å–å¾—ä¸­..."):
            try:
                search = GoogleSearch({
                    "q": question,
                    "api_key": serpapi_api_key,
                    "num": num_results,
                })
                results = search.get_dict()
                if "organic_results" not in results:
                    st.error("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.stop()
                st.session_state["search_results"] = results["organic_results"]
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if st.session_state["search_results"]:
    st.write("Googleæ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    if st.button("å›ç­”ã‚’ç”Ÿæˆ"):
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                organic_results = st.session_state["search_results"]
                extracted_texts = []
                for result in organic_results:
                    try:
                        link = result.get("link")
                        if link:
                            response = requests.get(link, timeout=10)
                            soup = BeautifulSoup(response.text, "html.parser")
                            texts = soup.stripped_strings
                            page_text = " ".join(texts)
                            extracted_texts.append(page_text)
                    except Exception as e:
                        st.warning(f"ãƒªãƒ³ã‚¯ {link} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

                if not extracted_texts:
                    st.error("æœ‰åŠ¹ãªæ¤œç´¢çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.stop()

                if search_method == "ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢":
                    text_splitter = RecursiveCharacterTextSplitter(
                        chunk_size=chunk_size,
                        chunk_overlap=chunk_overlap,
                        separators=["\n\n", "\n", " ", ""]
                    )
                    chunks = []
                    for text in extracted_texts:
                        chunks.extend(text_splitter.split_text(text))

                    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
                    with tempfile.TemporaryDirectory() as tempdir:
                        vectorstore = Chroma.from_texts(
                            texts=chunks,
                            embedding=embeddings,
                            persist_directory=os.path.join(tempdir, "chroma")
                        )
                        docs = vectorstore.similarity_search(question, k=4)
                        context = "\n\n".join([doc.page_content for doc in docs])

                elif search_method == "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢":
                    keywords = re.findall(r'\b\w+\b', question)
                    context = ""
                    for keyword in keywords:
                        # æ¤œç´¢ã¯æ—¢ã«å®Ÿè¡Œæ¸ˆã¿ãªã®ã§ã€ã“ã“ã§ã¯æ¤œç´¢ã‚’å®Ÿè¡Œã—ãªã„
                        # ä»£ã‚ã‚Šã«ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰æ¤œç´¢çµæœã‚’åˆ©ç”¨ã™ã‚‹
                        # ... (ã“ã®éƒ¨åˆ†ã¯ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å–å¾—ã™ã‚‹å‡¦ç†ãŒå¿…è¦) ...
                        context += "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®çµæœã‚’ã“ã“ã«è¿½åŠ " # placeholder


                llm = ChatOpenAI(
                    openai_api_key=openai_api_key,
                    model_name="gpt-3.5-turbo", # ãƒ¢ãƒ‡ãƒ«åã‚’ä¿®æ­£
                    temperature=0.5
                )
                messages = [
                    SystemMessage(content="You are a helpful assistant that provides information based on the provided context."),
                    HumanMessage(content=f"Context: {context}\n\nQuestion: {question}")
                ]
                response = llm(messages)
                st.success("**å›ç­”:**")
                st.write(response.content)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

